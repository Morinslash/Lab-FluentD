apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: fluentd
data:
  fluent.conf: |-
    @include pods-kind-fluent.conf
    #@include pods-fluent.conf
    @include filter-kubernetes-meta.conf
    @include filter-json.conf
    #@include filter-out-json.conf
    @include copy-file-elastic.conf
  pods-kind-fluent.conf: |- # kind cluster fluentd configuration, it differs from regular cluster
    <source>
      @type tail
      read_from_head true
      tag kubernetes.*
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      exclude_path ["/var/log/containers/fluent*","/var/log/containers/**_kube-system_**"]
      <parse>
        @type regexp
        #https://regex101.com/r/ZkOBTI/1
        expression ^(?<time>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.[^Z]*Z)\s(?<stream>[^\s]+)\s(?<character>[^\s])\s(?<message>.*)$
        #time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>
  pods-fluent.conf: |- # boilerplate for regular k8s cluster
    <source>
      @type tail
      read_from_head true
      tag kubernetes.*
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      exclude_path ["/var/log/containers/fluent*"]
      <parse>
        @type kubernetes
        @type "#{ENV['FLUENT_CONTAINER_TAIL_PARSER_TYPE'] || 'json'}"
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>
  filter-kubernetes-meta.conf: |- # add kubernetes metadata to the logs
    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
      kubernetes_url "#{ENV['FLUENT_FILTER_KUBERNETES_URL'] || 'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}"
      verify_ssl "#{ENV['KUBERNETES_VERIFY_SSL'] || true}"
      ca_file "#{ENV['KUBERNETES_CA_FILE']}"
      skip_labels "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_LABELS'] || 'false'}"
      skip_container_metadata "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_CONTAINER_METADATA'] || 'false'}"
      skip_master_url "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_MASTER_URL'] || 'false'}"
      skip_namespace_metadata "#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_NAMESPACE_METADATA'] || 'false'}"
    </filter>
  filter-json.conf: |- # filter to parse the json log message, field to pars is "message" with prefix "log-data"
    <filter **>
      @type parser
      key_name "message"
      reserve_data true
      reserve_time true
      hash_value_field "log-data"
      remove_key_name_field true
      replace_invalid_sequence true
      emit_invalid_record_to_error false
      <parse>
        @type json
      </parse>
    </filter>
  copy-file-elastic.conf: |- # output stream copy allows to duplicate logs and send to multiple storages
    <match **>
      @type copy
      <store>
        @type file
        path /tmp/file-test.log
      </store>
      <store>
        @type elasticsearch
        host "#{ENV['FLUENT_ELASTICSEARCH_HOST'] || 'elasticsearch.elastic-kibana'}"
        port "#{ENV['FLUENT_ELASTICSEARCH_PORT'] || '9200'}"
        index_name fluentd-k8s
        type_name fluentd
      </store>
    </match>